{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericpark/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18,resnet50,resnet101,resnet152\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'MODEL_NAME':\"resnet152\",\n",
    "    'Agumentations':\"blur, affin, dilation&erosion, bright&contrast\",\n",
    "    'data label added':\"label 5, label 6 added\",\n",
    "    'IMG_HEIGHT_SIZE':64,\n",
    "    'IMG_WIDTH_SIZE':224,\n",
    "    'EPOCHS':100,\n",
    "    'LEARNING_RATE':1e-3,\n",
    "    'BATCH_SIZE':128,\n",
    "    'NUM_WORKERS':4, # 본인의 GPU, CPU 환경에 맞게 설정\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_label_6.csv')\n",
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 개 단어 갯수 :  23703\n",
      "2 개 단어 갯수 :  28631\n",
      "3 개 단어 갯수 :  13514\n",
      "4 개 단어 갯수 :  9988\n",
      "5 개 단어 갯수 :  7464\n",
      "6 개 단어 갯수 :  5892\n"
     ]
    }
   ],
   "source": [
    "# 제공된 학습데이터 중 1글자 샘플들의 단어사전이 학습/테스트 데이터의 모든 글자를 담고 있으므로 학습 데이터로 우선 배치\n",
    "df['len'] = df['label'].str.len()\n",
    "train_v1 = df[df['len']==1]\n",
    "\n",
    "qw=[sum(df['len']==i) for i in range(1,7)]\n",
    "for k in range(1,7):\n",
    "    print(k,\"개 단어 갯수 : \",qw[k-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76094 13098\n",
      "2349\n",
      "2350\n"
     ]
    }
   ],
   "source": [
    "# 제공된 학습데이터 중 2글자 이상의 샘플들에 대해서 단어길이를 고려하여 Train (80%) / Validation (20%) 분할\n",
    "df = df[df['len']>1]\n",
    "train_v2, val, _, _ = train_test_split(df, df['len'], test_size=0.2, random_state=CFG['SEED'])\n",
    "\n",
    "# 학습 데이터로 우선 배치한 1글자 샘플들과 분할된 2글자 이상의 학습 샘플을 concat하여 최종 학습 데이터로 사용\n",
    "train = pd.concat([train_v1, train_v2])\n",
    "print(len(train), len(val))\n",
    "\n",
    "# 학습 데이터로부터 단어 사전(Vocabulary) 구축\n",
    "train_gt = [gt for gt in train['label']]\n",
    "train_gt = \"\".join(train_gt)\n",
    "letters = sorted(list(set(list(train_gt))))\n",
    "print(len(letters))\n",
    "\n",
    "vocabulary = [\"-\"] + letters\n",
    "print(len(vocabulary))\n",
    "idx2char = {k:v for k,v in enumerate(vocabulary, start=0)}\n",
    "char2idx = {v:k for k,v in idx2char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------\n",
    "# augmentation\n",
    "# albumentation 에 있는 agumentation 기법들 사용 \n",
    "def get_aug(p=0.5):\n",
    "    return A.Compose([\n",
    "        # blur\n",
    "        A.OneOf([\n",
    "         A.AdvancedBlur(rotate_limit=(90), p=p), \n",
    "         A.MedianBlur(blur_limit=(5),p=p),\n",
    "         A.GaussianBlur(blur_limit=(5,7),p=p),\n",
    "\n",
    "        ]),\n",
    "        # noise\n",
    "        A.OneOf([\n",
    "         A.RandomRain(blur_value=1,rain_type='heavy',p=p), # rain type torrential\n",
    "         A.GaussNoise(var_limit=(90.0,90.0),p=p),\n",
    "        ]),\n",
    "\n",
    "        # A.ElasticTransform(p=p)\n",
    "        A.ElasticTransform(always_apply=False, p=p, sigma=4.35, alpha_affine=5),\n",
    "        A.Sharpen(alpha=(0.7, 0.8), lightness=(0.8, 1.0), always_apply=False, p=p),\n",
    "        \n",
    "        # Birght and Contrast \n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.4,0.5),contrast_limit=(-0.4,0.5), p=p),\n",
    "\n",
    "        # CLAHE\n",
    "        A.CLAHE(clip_limit=4.0,tile_grid_size=(10,10),p=p),\n",
    "\n",
    "    ])\n",
    "\n",
    "#--------------------------------------\n",
    "# dataset class \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True,argument_mode=False,tfms=get_aug()):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.train_mode = train_mode\n",
    "        self.argument_mode = argument_mode\n",
    "        self.tfms = tfms\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_path_list[index]).convert('RGB')\n",
    "        \n",
    "\n",
    "        if self.argument_mode:\n",
    "            image = np.array(image) \n",
    "            aug = self.tfms(image=image)\n",
    "            image = aug['image']\n",
    "            image = Image.fromarray(image)\n",
    "            return image \n",
    "            #image = self.train_transform(image)\n",
    "\n",
    "\n",
    "        if self.train_mode:\n",
    "            #-------------------------------------------------------\n",
    "            # augmented added by eric\n",
    "            image = np.array(image) \n",
    "            aug = self.tfms(image=image)\n",
    "            image = aug['image']\n",
    "            image = Image.fromarray(image)\n",
    "            image = self.train_transform(image)\n",
    "        else:\n",
    "            image = self.test_transform(image)\n",
    "\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            text = self.label_list[index]\n",
    "            return image, text\n",
    "        else:\n",
    "            return image    \n",
    "\n",
    "    # Image Augmentation\n",
    "    def train_transform(self, image):\n",
    "        transform_ops = transforms.Compose([\n",
    "            transforms.Resize((CFG['IMG_HEIGHT_SIZE'],CFG['IMG_WIDTH_SIZE'])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "        return transform_ops(image)\n",
    "    \n",
    "    def test_transform(self, image):\n",
    "        transform_ops = transforms.Compose([\n",
    "            transforms.Resize((CFG['IMG_HEIGHT_SIZE'],CFG['IMG_WIDTH_SIZE'])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "        return transform_ops(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Load \n",
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=CFG['NUM_WORKERS'])\n",
    "\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['label'].values,train_mode=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=CFG['NUM_WORKERS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 64, 224]) ('달다', '찌', '출신', '뉵', '시일', '뛰어오르다', '거리', '키우다', '종교적', '위기감수성', '가능해지다', '지도자', '색다르다', '아예', '빌다', '고장', '기대', '웽', '병', '표시하다', '땝', '채우다', '궁금하다만점', '흰색태우다', '죙', '열', '낭', '튕', '고등학교', '행동하다', '툽', '솜', '단골', '반', '해물', '붸', '세월', '종이', '올바르다', '그대', '원피스', '사고', '거듭', '파도', '시끄럽다', '난방', '주민', '항', '음식물', '미리', '랍', '재즈', '공연하다포크', '책', '내밀다', '불과하다', '먹다기초적', '걜', '인간적', '케첩', '종교적', '통과하다', '븀', '갈다', '걱정되다', '확신하다읽다', '도와주다논쟁', '기후', '평화', '언', '깔끔하다숙소', '찾아보다', '시끄럽다', '분리되다', '파일', '배', '두려워하다', '쌍둥이', '접시', '경험', '굳', '비닐', '기획지리산', '이내', '식히다', '벌어지다', '전망하다', '다가서다', '사이사이', '기술', '독하다', '불안', '각', '조사', '연두색', '달다', '뛰어나다잘못', '힛', '되게', '위기', '끎', '졈', '전반', '언덕', '휴지', '포도주', '자극하다', '프로', '소용없다순수', '뜰', '기성', '중단하다시야', '탑', '결정되다전반', '킬로그램', '성격장애인', '나란히', '팩', '설날불리다', '선생님', '차림', '뛰어놀다곧잘', '정말', '두', '고르다', '이십', '자격증', '풍경')\n"
     ]
    }
   ],
   "source": [
    "image_batch, text_batch = iter(train_loader).next()\n",
    "print(image_batch.size(), text_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Define \n",
    "class RecognitionModel(nn.Module):\n",
    "    def __init__(self, num_chars=len(char2idx), rnn_hidden_size=256):\n",
    "        super(RecognitionModel, self).__init__()\n",
    "        self.num_chars = num_chars\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "\n",
    "        #---------------------------------------\n",
    "        # RESNET\n",
    "        # pretraine 된 resnet 152 사용 \n",
    "        resnet = resnet152(pretrained=True)\n",
    "        #---------------------------------------\n",
    "\n",
    "        \n",
    "        # CNN Feature Extract\n",
    "        resnet_modules = list(resnet.children())[:-3]\n",
    "        \n",
    "        self.feature_extract = nn.Sequential(\n",
    "            *resnet_modules,\n",
    "            nn.Conv2d(1024, 512, kernel_size=(3,6), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.linear1 = nn.Linear(2048, rnn_hidden_size)\n",
    "\n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_size=rnn_hidden_size, \n",
    "                            hidden_size=rnn_hidden_size,\n",
    "                            bidirectional=True, \n",
    "                            batch_first=True)\n",
    "        self.linear2 = nn.Linear(self.rnn_hidden_size*2, num_chars)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN\n",
    "        x = self.feature_extract(x) # [batch_size, channels, height, width]\n",
    "        x = x.permute(0, 3, 1, 2) # [batch_size, width, channels, height]\n",
    "         \n",
    "\n",
    "        # resnet 50 #=============================== x shape  torch.Size([256, 11, 2048])\n",
    "        batch_size = x.size(0)\n",
    "        T = x.size(1)\n",
    "\n",
    "        x = x.view(batch_size, T, -1) # [batch_size, T==width, num_features==channels*height]\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        # RNN\n",
    "        x, hidden = self.rnn(x)\n",
    "        \n",
    "        output = self.linear2(x)\n",
    "        output = output.permute(1, 0, 2) # [T==10, batch_size, num_classes==num_features]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CTC Loss \n",
    "criterion = nn.CTCLoss(blank=0) # idx 0 : '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_batch(text_batch):\n",
    "    text_batch_targets_lens = [len(text) for text in text_batch]\n",
    "    text_batch_targets_lens = torch.IntTensor(text_batch_targets_lens)\n",
    "    \n",
    "    text_batch_concat = \"\".join(text_batch)\n",
    "    text_batch_targets = [char2idx[c] for c in text_batch_concat]\n",
    "    text_batch_targets = torch.IntTensor(text_batch_targets)\n",
    "    \n",
    "    return text_batch_targets, text_batch_targets_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(text_batch, text_batch_logits):\n",
    "    \"\"\"\n",
    "    text_batch: list of strings of length equal to batch size\n",
    "    text_batch_logits: Tensor of size([T, batch_size, num_classes])\n",
    "    \"\"\"\n",
    "    text_batch_logps = F.log_softmax(text_batch_logits, 2) # [T, batch_size, num_classes]  \n",
    "    text_batch_logps_lens = torch.full(size=(text_batch_logps.size(1),), \n",
    "                                       fill_value=text_batch_logps.size(0), \n",
    "                                       dtype=torch.int32).to(device) # [batch_size] \n",
    "\n",
    "    text_batch_targets, text_batch_targets_lens = encode_text_batch(text_batch)\n",
    "    loss = criterion(text_batch_logps, text_batch_targets, text_batch_logps_lens, text_batch_targets_lens)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer,scheduler, device):\n",
    "    model.to(device)\n",
    "    \n",
    "    best_loss = 999999\n",
    "    best_model = None\n",
    "\n",
    "    #submit = pd.read_csv('/home/eric/0.Data/0.dacon_ocr/sample_submission.csv')\n",
    "    submit = {'label_gt':[],'label_pred':[]}\n",
    "    submit = pd.DataFrame(submit)\n",
    "\n",
    "\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "\n",
    "\n",
    "        #---------------------------------------\n",
    "        # df \n",
    "        df = pd.read_csv('../data/train_label_6.csv')\n",
    "        del df['Unnamed: 0']\n",
    "        df['len'] = df['label'].str.len()\n",
    "        train_v1 = df[df['len']==1]\n",
    "        df = df[df['len']>1]\n",
    "\n",
    "        # train test split stratify\n",
    "        train_v2, val, _, _ = train_test_split(df, df['len'], test_size=0.2, stratify=df['len'])\n",
    "        train = pd.concat([train_v1, train_v2])\n",
    "        train_gt = [gt for gt in train['label']]\n",
    "        train_gt = \"\".join(train_gt)\n",
    "        letters = sorted(list(set(list(train_gt))))\n",
    "        vocabulary = [\"-\"] + letters\n",
    "        idx2char = {k:v for k,v in enumerate(vocabulary, start=0)}\n",
    "        char2idx = {v:k for k,v in idx2char.items()}\n",
    "\n",
    "        # dataset & loader \n",
    "        train_dataset = CustomDataset(train['img_path'].values, train['label'].values,train_mode=True)\n",
    "        train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=CFG['NUM_WORKERS'])\n",
    "\n",
    "        val_dataset = CustomDataset(val['img_path'].values, val['label'].values,train_mode=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=CFG['NUM_WORKERS'])\n",
    "\n",
    "\n",
    "        for image_batch, text_batch in tqdm(iter(train_loader)):\n",
    "            image_batch = image_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            text_batch_logits = model(image_batch)\n",
    "            loss = compute_loss(text_batch, text_batch_logits)\n",
    "        \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        _train_loss = np.mean(train_loss)\n",
    "\n",
    "        print(\"# Validation\")\n",
    "        _val_loss,_val_labels,_val_preds = validation(model, val_loader, device)\n",
    "\n",
    "        print(\"_val_labels\",len(_val_labels))\n",
    "        #print(\"label_pred\",_val_preds)\n",
    "\n",
    "        submit['label_gt']   = _val_labels\n",
    "        submit['label_pred'] = _val_preds\n",
    "        submit['label_pred'] = submit['label_pred'].apply(correct_prediction)\n",
    "        \n",
    "        #submit.to_csv(f\"/home/eric/1.Source/00.Ocr/0.baseline_cnn_rnn/tmp/train_exp/sharpen_v1/result_{epoch}.csv\",index=False) \n",
    "        \n",
    "        #--------------------------------------------------\n",
    "        # Accuracy Metric by eric \n",
    "        # baseline 에 평가메트릭이 없으므로, 자체적으로 Accuracy 메트릭 코드 작성\n",
    "        # \n",
    "        az = submit\n",
    "\n",
    "        acc_correct = 0\n",
    "        acc_wrong = 0\n",
    "        predict_length_wrong=0\n",
    "\n",
    "        D = {'1':0,'2':0,'3':0,'4':0,'5':0,'6':0}\n",
    "        Q = {'1':[0,0],'2':[0,0],'3':[0,0],'4':[0,0],'5':[0,0],'6':[0,0]}\n",
    "        for gt, pred in zip(az['label_gt'],az['label_pred']):\n",
    "            #print(\"gt\", [i for i in gt])\n",
    "            #print(\"pred\", [z for z in pred])\n",
    "            \n",
    "            try:\n",
    "                E = [i for i in gt]\n",
    "                W =  [z for z in pred]\n",
    "\n",
    "                for i in range(len(E)):\n",
    "                    Q[str(len(E))][1] +=1\n",
    "                    if E[i] == W[i]:\n",
    "                        acc_correct +=1\n",
    "                        Q[str(len(E))][0] +=1\n",
    "                    else:\n",
    "                        acc_wrong +=1\n",
    "                        \n",
    "            except:\n",
    "                #print(\"predict_length_wrong case!!\")\n",
    "                predict_length_wrong+=1\n",
    "                D[str(len([i for i in gt]))] +=1 \n",
    "\n",
    "        print(\"#---------------------------------\")\n",
    "        print(\"total accuracy : \", acc_correct/(acc_correct + acc_wrong))\n",
    "        #wandb.log({\"total accuracy\" : acc_correct/(acc_correct + acc_wrong)})\n",
    "\n",
    "        print(\"accuracy by word len : \", Q )\n",
    "\n",
    "        for i in range(2,7):\n",
    "            print(\"accuracy by word len percent : \", f\"{i} : \", Q[str(i)][0]/Q[str(i)][1])\n",
    "            #wandb.log({\"accuracy by word len percent {i}\" :  Q[str(i)][0]/Q[str(i)][1]})\n",
    "            # 1자리 수 문자는 train 으로 다 들어가므로 validation 에 들어가지 않음 \n",
    "        print(\"pred length wrong case : \",predict_length_wrong)\n",
    "        print(\"total case : \",len(az['label_gt']))\n",
    "        print(\"Wrong cases by len : \",D)\n",
    "\n",
    "        print(f'Epoch : [{epoch}] Train CTC Loss : [{_train_loss:.5f}] Val CTC Loss : [{_val_loss:.5f}]')\n",
    "        #print(\"Validation labels : \",submit['label_gt']  )\n",
    "        #print(\"Validation preds : \", submit['label'])\n",
    "\n",
    "        #wandb.log({\"Train CTC Loss :\" : _train_loss,\"Val CTC Loss : \" : _val_loss }, step=epoch)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_loss)\n",
    "        \n",
    "        if best_loss > _val_loss:\n",
    "            best_loss = _val_loss\n",
    "            best_model = model\n",
    "            print(\"model save ########### \")\n",
    "            torch.save(best_model.state_dict(), f\"../exp/0.resnet152_rnn_AUGCombo_DataAdd_STR_Distortion_v1_{epoch}.pth\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Accuracy_Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--------------------------------------\n",
    "# # Accuracy Metric by eric \n",
    "# 위의 Accuracy Metric 을 검증하기 위한 코드 \n",
    "# #--------------------------------------\n",
    "\n",
    "\n",
    "# az = pd.read_csv(\"/home/eric/1.Source/00.Ocr/0.baseline_cnn_rnn/tmp/val_gt_pred_2.csv\")\n",
    "\n",
    "# acc_correct = 0\n",
    "# acc_wrong = 0\n",
    "# predict_length_wrong=0\n",
    "\n",
    "# D = {'1':0,'2':0,'3':0,'4':0,'5':0,'6':0}\n",
    "# Q = {'1':[0,0],'2':[0,0],'3':[0,0],'4':[0,0],'5':[0,0],'6':[0,0]}\n",
    "# for gt, pred in zip(az['label_gt'],az['label_pred']):\n",
    "#     #print(\"gt\", [i for i in gt])\n",
    "#     #print(\"pred\", [z for z in pred])\n",
    "    \n",
    "#     try:\n",
    "#         E = [i for i in gt]\n",
    "#         W =  [z for z in pred]\n",
    "\n",
    "#         for i in range(len(E)):\n",
    "#             Q[str(len(E))][1] +=1\n",
    "#             if E[i] == W[i]:\n",
    "#                 acc_correct +=1\n",
    "#                 Q[str(len(E))][0] +=1\n",
    "#             else:\n",
    "#                 acc_wrong +=1\n",
    "                \n",
    "#     except:\n",
    "#         #print(\"predict_length_wrong case!!\")\n",
    "#         predict_length_wrong+=1\n",
    "#         D[str(len([i for i in gt]))] +=1 \n",
    "\n",
    "# print(\"#---------------------------------\")\n",
    "# print(\"total accuracy : \", acc_correct/(acc_correct + acc_wrong))\n",
    "\n",
    "# print(\"accuracy by word len : \", Q )\n",
    "\n",
    "# for i in range(2,7):\n",
    "#     print(\"accuracy by word len percent : \", f\"{i} : \", Q[str(i)][0]/Q[str(i)][1])\n",
    "#     # 1자리 수 문자는 train 으로 다 들어가므로 validation 에 들어가지 않음 \n",
    "# print(\"pred length wrong case : \",predict_length_wrong)\n",
    "# print(\"total case : \",len(az['label_gt']))\n",
    "# print(\"Wrong cases by len : \",D)\n",
    "            \n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Utils_Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "# 대회 기본 제공 inference 후처리 코드와 동일  \n",
    "# 샘플 별 추론결과를 독립적으로 후처리\n",
    "def remove_duplicates(text):\n",
    "    if len(text) > 1:\n",
    "        letters = [text[0]] + [letter for idx, letter in enumerate(text[1:], start=1) if text[idx] != text[idx-1]]\n",
    "    elif len(text) == 1:\n",
    "        letters = [text[0]]\n",
    "    else:\n",
    "        return \"\"\n",
    "    return \"\".join(letters)\n",
    "\n",
    "def correct_prediction(word):\n",
    "    parts = word.split(\"-\")\n",
    "    parts = [remove_duplicates(part) for part in parts]\n",
    "    corrected_word = \"\".join(parts)\n",
    "    return corrected_word\n",
    "\n",
    "def decode_predictions(text_batch_logits):\n",
    "    text_batch_tokens = F.softmax(text_batch_logits, 2).argmax(2) # [T, batch_size]\n",
    "    text_batch_tokens = text_batch_tokens.numpy().T # [batch_size, T]\n",
    "\n",
    "    text_batch_tokens_new = []\n",
    "    for text_tokens in text_batch_tokens:\n",
    "        text = [idx2char[idx] for idx in text_tokens]\n",
    "        text = \"\".join(text)\n",
    "        text_batch_tokens_new.append(text)\n",
    "\n",
    "    return text_batch_tokens_new\n",
    "    \n",
    "def validation(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image_batch, text_batch in tqdm(iter(val_loader)):\n",
    "            image_batch = image_batch.to(device)\n",
    "            \n",
    "            text_batch_logits = model(image_batch)\n",
    "            loss = compute_loss(text_batch, text_batch_logits)\n",
    "            #--------------------------------\n",
    "            # eric \n",
    "            text_batch_pred = decode_predictions(text_batch_logits.cpu())\n",
    "            val_preds.extend(text_batch_pred)\n",
    "            val_labels.extend(text_batch)\n",
    "            val_loss.append(loss.item())\n",
    "    \n",
    "    _val_loss = np.mean(val_loss)\n",
    "    return _val_loss,val_labels,val_preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 50/595 [00:08<01:34,  5.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/e/01.Eric/02.Source/20.[Dacon]_Source_Code/01.Baseline_CRNN/[OCR]_[MODEL_1]_res152_rcnn.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(params \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m CFG[\u001b[39m\"\u001b[39m\u001b[39mLEARNING_RATE\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,threshold_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mabs\u001b[39m\u001b[39m'\u001b[39m,min_lr\u001b[39m=\u001b[39m\u001b[39m1e-8\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m infer_model \u001b[39m=\u001b[39m train(model, optimizer, scheduler, device)\n",
      "\u001b[1;32m/mnt/e/01.Eric/02.Source/20.[Dacon]_Source_Code/01.Baseline_CRNN/[OCR]_[MODEL_1]_res152_rcnn.ipynb Cell 26\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     train_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39;49mitem())\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m _train_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(train_loss)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m# Validation\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RecognitionModel()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, scheduler, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id                     img_path\n",
      "0      TEST_00000  ../data/test/TEST_00000.png\n",
      "1      TEST_00001  ../data/test/TEST_00001.png\n",
      "2      TEST_00002  ../data/test/TEST_00002.png\n",
      "3      TEST_00003  ../data/test/TEST_00003.png\n",
      "4      TEST_00004  ../data/test/TEST_00004.png\n",
      "...           ...                          ...\n",
      "74116  TEST_74116  ../data/test/TEST_74116.png\n",
      "74117  TEST_74117  ../data/test/TEST_74117.png\n",
      "74118  TEST_74118  ../data/test/TEST_74118.png\n",
      "74119  TEST_74119  ../data/test/TEST_74119.png\n",
      "74120  TEST_74120  ../data/test/TEST_74120.png\n",
      "\n",
      "[74121 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# predict \n",
    "\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "bl = []\n",
    "for i,row in test.iterrows():\n",
    "    qw = row['img_path']\n",
    "    a = qw.replace(\"./test/\", \"../data/test/\")\n",
    "    bl.append(a)\n",
    "\n",
    "test['img_path'] = bl\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test['img_path'].values, None,train_mode=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=CFG['NUM_WORKERS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(text_batch_logits):\n",
    "    text_batch_tokens = F.softmax(text_batch_logits, 2).argmax(2) # [T, batch_size]\n",
    "    text_batch_tokens = text_batch_tokens.numpy().T # [batch_size, T]\n",
    "\n",
    "    text_batch_tokens_new = []\n",
    "    for text_tokens in text_batch_tokens:\n",
    "        text = [idx2char[idx] for idx in text_tokens]\n",
    "        text = \"\".join(text)\n",
    "        text_batch_tokens_new.append(text)\n",
    "\n",
    "    return text_batch_tokens_new\n",
    "\n",
    "def inference(model, test_loader, device,load=False):\n",
    "    if load:\n",
    "    \n",
    "        model_path = \"../06.Model_Weights/0.resnet152_last_v1_70.pth\"\n",
    "        model.load_state_dict(torch.load(model_path,map_location='cuda:0'))\n",
    "        print(\"### model loaded ###\")\n",
    "        print(\"model : \",model_path)\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for image_batch in tqdm(iter(test_loader)):\n",
    "            image_batch = image_batch.to(device)\n",
    "            \n",
    "            text_batch_logits = model(image_batch)\n",
    "            \n",
    "            text_batch_pred = decode_predictions(text_batch_logits.cpu())\n",
    "            \n",
    "            preds.extend(text_batch_pred)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### model loaded ###\n",
      "model :  ../06.Model_Weights/0.resnet152_last_v1_70.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 19/580 [00:01<00:56,  9.97it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/e/01.Eric/02.Source/20.[Dacon]_Source_Code/01.Baseline_CRNN/[OCR]_[MODEL_1]_res152_rcnn.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m RecognitionModel()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m predictions \u001b[39m=\u001b[39m inference(model,test_loader, device,load\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32m/mnt/e/01.Eric/02.Source/20.[Dacon]_Source_Code/01.Baseline_CRNN/[OCR]_[MODEL_1]_res152_rcnn.ipynb Cell 32\u001b[0m in \u001b[0;36minference\u001b[0;34m(model, test_loader, device, load)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m         image_batch \u001b[39m=\u001b[39m image_batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m         text_batch_logits \u001b[39m=\u001b[39m model(image_batch)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m         text_batch_pred \u001b[39m=\u001b[39m decode_predictions(text_batch_logits\u001b[39m.\u001b[39;49mcpu())\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m         preds\u001b[39m.\u001b[39mextend(text_batch_pred)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mreturn\u001b[39;00m preds\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RecognitionModel()\n",
    "predictions = inference(model,test_loader, device,load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission \n",
    "# 샘플 별 추론결과를 독립적으로 후처리\n",
    "def remove_duplicates(text):\n",
    "    if len(text) > 1:\n",
    "        letters = [text[0]] + [letter for idx, letter in enumerate(text[1:], start=1) if text[idx] != text[idx-1]]\n",
    "    elif len(text) == 1:\n",
    "        letters = [text[0]]\n",
    "    else:\n",
    "        return \"\"\n",
    "    return \"\".join(letters)\n",
    "\n",
    "def correct_prediction(word):\n",
    "    parts = word.split(\"-\")\n",
    "    parts = [remove_duplicates(part) for part in parts]\n",
    "    corrected_word = \"\".join(parts)\n",
    "    return corrected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/e/01.Eric/02.Source/20.[Dacon]_Source_Code/01.Baseline_CRNN/[OCR]_[MODEL_1]_res152_rcnn.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m submit \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../data/sample_submission.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m submit[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m predictions\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/01.Eric/02.Source/20.%5BDacon%5D_Source_Code/01.Baseline_CRNN/%5BOCR%5D_%5BMODEL_1%5D_res152_rcnn.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m submit[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m submit[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(correct_prediction)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "submit['label'] = predictions\n",
    "submit['label'] = submit['label'].apply(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../07.Submission_Files/test_[ensemble][2]resnet152_DataAdd_STR_last.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>남말</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>상활</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>받아들이다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>바구니</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>살</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEST_00005</td>\n",
       "      <td>빼놓다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEST_00006</td>\n",
       "      <td>인식하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEST_00007</td>\n",
       "      <td>센터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEST_00008</td>\n",
       "      <td>소풍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEST_00009</td>\n",
       "      <td>광주</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TEST_00010</td>\n",
       "      <td>나나</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TEST_00011</td>\n",
       "      <td>위험</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEST_00012</td>\n",
       "      <td>도도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TEST_00013</td>\n",
       "      <td>슬표</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TEST_00014</td>\n",
       "      <td>괴로워하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TEST_00015</td>\n",
       "      <td>카드</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TEST_00016</td>\n",
       "      <td>합치다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TEST_00017</td>\n",
       "      <td>다정하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TEST_00018</td>\n",
       "      <td>흔자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TEST_00019</td>\n",
       "      <td>가능하다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label\n",
       "0   TEST_00000     남말\n",
       "1   TEST_00001     상활\n",
       "2   TEST_00002  받아들이다\n",
       "3   TEST_00003    바구니\n",
       "4   TEST_00004      살\n",
       "5   TEST_00005    빼놓다\n",
       "6   TEST_00006   인식하다\n",
       "7   TEST_00007     센터\n",
       "8   TEST_00008     소풍\n",
       "9   TEST_00009     광주\n",
       "10  TEST_00010     나나\n",
       "11  TEST_00011     위험\n",
       "12  TEST_00012     도도\n",
       "13  TEST_00013     슬표\n",
       "14  TEST_00014  괴로워하다\n",
       "15  TEST_00015     카드\n",
       "16  TEST_00016    합치다\n",
       "17  TEST_00017   다정하다\n",
       "18  TEST_00018     흔자\n",
       "19  TEST_00019   가능하다"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit[0:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e1a29d28f21026522f6531158df36c64b2f3fd75cf0197f93c2662c81180c2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
